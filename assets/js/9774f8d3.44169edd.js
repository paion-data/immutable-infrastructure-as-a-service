"use strict";(self.webpackChunkhashicorp_aws=self.webpackChunkhashicorp_aws||[]).push([[8475],{6880:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>h});var i=t(4848),s=t(8453);const o={slug:"continuous-delivery",title:"Continuous Delivery",authors:["continuousdelivery.com","jiaqi","sten-pittet"],tags:["Continuous Delivery"]},a=void 0,r={permalink:"/hashicorp-aws/blog/continuous-delivery",editUrl:"https://github.com/QubitPi/hashicorp-aws/tree/master/docs/blog/2022-08-31-continuous-delivery/index.md",source:"@site/blog/2022-08-31-continuous-delivery/index.md",title:"Continuous Delivery",description:"[//]: # (Copyright Jiaqi Liu)",date:"2022-08-31T00:00:00.000Z",formattedDate:"August 31, 2022",tags:[{label:"Continuous Delivery",permalink:"/hashicorp-aws/blog/tags/continuous-delivery"}],readingTime:29.365,hasTruncateMarker:!0,authors:[{name:"continuousdelivery.com",title:"Origin",url:"https://continuousdelivery.com/",imageURL:"https://continuousdelivery.com/images/cd-book.png",key:"continuousdelivery.com"},{name:"Jiaqi Liu",title:"Maintainer of hashicorp-aws",url:"https://github.com/QubitPi",imageURL:"https://avatars.githubusercontent.com/u/16126939?v=4",key:"jiaqi"},{name:"Sten Pittet",url:"https://www.atlassian.com/continuous-delivery/software-testing/types-of-software-testing",imageURL:"https://wac-cdn.atlassian.com/dam/jcr:57a8bbb8-4f5c-46fc-9ceb-224cf79af3d8/Screen%20Shot%202017-04-14%20at%2010.43.26%20AM.png?cdnVersion=998",key:"sten-pittet"}],frontMatter:{slug:"continuous-delivery",title:"Continuous Delivery",authors:["continuousdelivery.com","jiaqi","sten-pittet"],tags:["Continuous Delivery"]},unlisted:!1,prevItem:{title:"Nexus 3 Repository Manager OSS",permalink:"/hashicorp-aws/blog/nexus"},nextItem:{title:"Deploying v.s. Releasing",permalink:"/hashicorp-aws/blog/deploying-vs-releasing"}},l={authorsImageUrls:[void 0,void 0,void 0]},h=[{value:"What is Continuous Delivery",id:"what-is-continuous-delivery",level:2},{value:"Why Continuous Delivery",id:"why-continuous-delivery",level:3},{value:"Principles",id:"principles",level:2},{value:"Build Quality In",id:"build-quality-in",level:3},{value:"Work in Small Batches",id:"work-in-small-batches",level:3},{value:"Relentlessly Pursue Continuous Improvement",id:"relentlessly-pursue-continuous-improvement",level:3},{value:"Everyone is Responsible",id:"everyone-is-responsible",level:3},{value:"Foundations - Prerequisites for Continuous Delivery",id:"foundations---prerequisites-for-continuous-delivery",level:2},{value:"Configuration Management",id:"configuration-management",level:3},{value:"Configuration Management Learning Resources",id:"configuration-management-learning-resources",level:4},{value:"Continuous Integration",id:"continuous-integration",level:3},{value:"Continuous Integration Learning Resources",id:"continuous-integration-learning-resources",level:4},{value:"Continuous Testing",id:"continuous-testing",level:3},{value:"Different Types of Software Testing",id:"different-types-of-software-testing",level:4},{value:"Unit Tests",id:"unit-tests",level:5},{value:"Integration Tests",id:"integration-tests",level:5},{value:"Functional Tests",id:"functional-tests",level:5},{value:"End-to-End Tests",id:"end-to-end-tests",level:5},{value:"Acceptance Tests",id:"acceptance-tests",level:5},{value:"Performance Tests",id:"performance-tests",level:5},{value:"Smoke Tests",id:"smoke-tests",level:5},{value:"Implementing Continuous Delivery",id:"implementing-continuous-delivery",level:2},{value:"Evolutionary Architecture",id:"evolutionary-architecture",level:3},{value:"Patterns",id:"patterns",level:3},{value:"The Deployment Pipeline",id:"the-deployment-pipeline",level:4},{value:"Patterns for Low-Risk Releases",id:"patterns-for-low-risk-releases",level:3}];function c(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",em:"em",h2:"h2",h3:"h3",h4:"h4",h5:"h5",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Continuous delivery is an approach where teams release quality products frequently and predictably from source code\nrepository to production in an automated fashion."}),"\n",(0,i.jsx)(n.h2,{id:"what-is-continuous-delivery",children:"What is Continuous Delivery"}),"\n",(0,i.jsxs)(n.p,{children:["Continuous Delivery is the ability to get changes of all types - including new features, configuration changes, bug\nfixes and experiments - into production, or into the hands of users, ",(0,i.jsx)(n.em,{children:"safely"})," and ",(0,i.jsx)(n.em,{children:"quickly"})," in a ",(0,i.jsx)(n.em,{children:"sustainable"})," way."]}),"\n",(0,i.jsx)(n.p,{children:"The goal of continuous delivery is to make deployments - whether of a large-scale distributed system, a complex\nproduction environment, an embedded system, or an app - predictable, routine affairs that can be performed on demand."}),"\n",(0,i.jsx)(n.p,{children:'We achieve all this by ensuring our code is always in a deployable state, even in the face of teams of thousands of\ndevelopers making changes on a daily basis. We thus completely eliminate the integration, testing and hardening phases\nthat traditionally followed "dev complete", as well as code freezes.'}),"\n",(0,i.jsx)(n.h3,{id:"why-continuous-delivery",children:"Why Continuous Delivery"}),"\n",(0,i.jsxs)(n.p,{children:["It is often assumed that if we want to deploy software more frequently, we must accept lower levels of stability and\nreliability in our systems. In fact, peer-reviewed research shows that this is not the case. High performance teams\nconsistently deliver services faster and more reliably than their low performing competition. This is true even in\nhighly regulated domains such as ",(0,i.jsx)(n.a,{href:"https://www.youtube.com/watch?v=eMS97X5ZTGc",children:"financial services"})," and\n",(0,i.jsx)(n.a,{href:"https://www.youtube.com/watch?v=QwHVlJtqhaI",children:"government"}),". This capability provides an incredible competitive advantage\nfor organizations that are willing to invest the effort to pursue it."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Firms with high-performing IT organizations were twice as likely to exceed their profitability, market share and\nproductivity goals."}),"\n",(0,i.jsx)(n.li,{children:"High performers achieved higher levels of both throughput and stability."}),"\n",(0,i.jsx)(n.li,{children:"The use of continuous delivery practices including version control, continuous integration, and test automation\npredicts higher IT performance."}),"\n",(0,i.jsx)(n.li,{children:"Culture is measurable and predicts job satisfaction and organizational performance."}),"\n",(0,i.jsx)(n.li,{children:"Continuous Delivery measurably reduces both deployment pain and team burnout."}),"\n"]})}),"\n",(0,i.jsx)(n.p,{children:"The practices at the heart of continuous delivery help us achieve several important benefits:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Low risk releases"}),". The primary goal of continuous delivery is to make software deployments painless, low-risk\nevents that can be performed at any time, on demand. By applying ",(0,i.jsx)(n.a,{href:"#patterns",children:"patterns"})," such as ",(0,i.jsx)(n.strong,{children:"blue-green\ndeployments"})," it is relatively straightforward to achieve zero-downtime deployments that are undetectable to users."]}),"\n",(0,i.jsx)(n.p,{children:":::info blue-green deployment"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Error loading blue-green-deployments.png ",src:t(9908).A+"",width:"953",height:"607"})}),"\n",(0,i.jsxs)(n.p,{children:["One of the challenges with automating deployment is the cut-over itself, taking software from the final stage of\ntesting to live production. We usually need to do this quickly in order to minimize downtime. The blue-green\ndeployment approach does this by ensuring we have ",(0,i.jsx)(n.strong,{children:"two production environments"}),", as identical as possible. At any\ntime one of them, let's say blue for the example, is live. As we prepare a new release of our software we do our\nfinal stage of testing in the green environment. Once the software is working in the green environment, we switch the\nrouter so that all incoming requests go to the green environment - the blue one is now idle."]}),"\n",(0,i.jsx)(n.p,{children:"Blue-green deployment also gives us a rapid way to rollback - if anything goes wrong we switch the router back to\nour blue environment. There's still the issue of dealing with missed transactions while the green environment was\nlive, but depending on our design we may be able to feed transactions to both environments in such a way as to keep\nthe blue environment as a backup when the green is live. Or we may be able to put the application in read-only mode\nbefore cut-over, run it for a while in read-only mode, and then switch it to read-write mode. That may be enough to\nflush out many outstanding issues."}),"\n",(0,i.jsx)(n.p,{children:"The two environments need to be different but as identical as possible. In some situations they can be different\npieces of hardware, or they can be different virtual machines running on the same (or different) hardware. They can\nalso be a single operating environment partitioned into separate zones with separate IP addresses for the two slices."}),"\n",(0,i.jsxs)(n.p,{children:["Once we've put our green environment live and we're happy with its stability, we then use the blue environment as\nour ",(0,i.jsx)(n.strong,{children:"staging environment"})," for the final testing step for our next deployment. When we are ready for our next\nrelease, we switch from green to blue in the same way that we did from blue to green earlier. That way both green and\nblue environments are regularly cycling between live, previous version (for rollback) and staging the next version."]}),"\n",(0,i.jsx)(n.p,{children:"An advantage of this approach is that it's the same basic mechanism as we need to get a hot-standby working. Hence\nthis allows us to test our disaster-recovery procedure on every release."}),"\n",(0,i.jsx)(n.p,{children:"The fundamental idea is to have two easily switchable environments to switch between, there are plenty of ways to vary\nthe details. One project did the switch by bouncing the web server rather than working on the router. Another\nvariation would be to use the same database, making the blue-green switches for web and domain layers."}),"\n",(0,i.jsxs)(n.p,{children:["Databases can often be a challenge with this technique, particularly when we need to change the schema to support a\nnew version of the software. The trick is to ",(0,i.jsx)(n.strong,{children:"separate the deployment of schema changes from application upgrades"}),".\nSo first apply a database refactoring to change the schema to support both the new and old version of the application,\ndeploy that, check everything is working fine so we have a rollback point, then deploy the new version of the\napplication. (And when the upgrade has bedded down remove the database support for the old version.)\n:::"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Faster time to market"}),". It's common for the integration and test/fix phase of the traditional phased software\ndelivery lifecycle to consume weeks to even months. When teams work together to automate the build and deployment,\nenvironment provisioning, and regression testing process, developers can incorporate integration and regression\ntesting into their daily work and completely remove these phases. We also avoid the large amount of re-work that\nplague the phased approach."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Higher quality and Better products"}),". When developers have automated tools that discover regressions within minutes,\nteams are freed to ",(0,i.jsx)(n.strong,{children:"focus their effort on user research and higher level testing activities"})," such as exploratory\ntesting, usability testing, and performance and security testing. By building a deployment pipeline, these activities\ncan be performed continuously throughout the delivery process, ensuring quality is built into products and services\nfrom the beginning. Continuous delivery makes it economic to work in small batches. This means we can get feedback\nfrom users throughout the delivery lifecycle based on working software."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Lower costs"}),". Any successful software product or service will evolve significantly over the course of its lifetime.\nBy investing in build, test, deployment and environment automation, we substantially reduce the cost of making and\ndelivering incremental changes to software by ",(0,i.jsx)(n.strong,{children:"eliminating many of the fixed costs"})," associated with the release\nprocess."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Happier teams"}),". Continuous Delivery makes releases less painful and reduces team burnout. Furthermore, when we\nrelease more frequently, software delivery teams can engage more actively with users, learn which ideas work and which\ndon't, and see first-hand then outcomes of the work they have done. By removing low-value painful activities\naccociated with software delivery, we can fodus on what we care about most - continuous delighting our users."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'Continuous delivery is about continuous, daily improvement - the constant discipline of pursuing higher performance by\nfollowing the heuristic "if it hurts, do it more often, and bring the pain forward."'})}),"\n",(0,i.jsx)(n.h2,{id:"principles",children:"Principles"}),"\n",(0,i.jsx)(n.p,{children:"There are five principles at the heart of continuous delivery:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Build quality in"}),"\n",(0,i.jsx)(n.li,{children:"Work in small batches"}),"\n",(0,i.jsx)(n.li,{children:"Computers perform repetitive tasks, people solve problems"}),"\n",(0,i.jsx)(n.li,{children:"Relentlessly pursue continuous improvement"}),"\n",(0,i.jsx)(n.li,{children:"Everyone is responsible"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"It's easy to get bogged down in the details of implementing continuous delivery - tools, architecture, practices,\npolitics - if you find yourself lost, try revisiting these principles and you may find it helps you refocus on what's\nimportant."}),"\n",(0,i.jsx)(n.h3,{id:"build-quality-in",children:"Build Quality In"}),"\n",(0,i.jsxs)(n.p,{children:["W. Edwards Deming, a key figure in the history of the Lean movement, offered\n",(0,i.jsx)(n.a,{href:"https://deming.org/explore/fourteen-points",children:"14 key principles"}),' for management. Principle three states, "Cease\ndependence on inspection to achieve quality. Eliminate the need for inspection on a mass basis by building quality into\nthe product in the first place".']}),"\n",(0,i.jsx)(n.p,{children:"It's much cheaper to fix problems and defects if we find them immediately - ideally before they are ever checked into\nversion control, by running automated tests locally. Finding defects downstream through inspection (such as manual\ntesting) is time-consuming, requiring significant triage. Then we must fix the defect, trying to recall what we were\nthinking when we introduced the problem days or perhaps even weeks ago."}),"\n",(0,i.jsx)(n.p,{children:"Creating and evolving feedback loops to detect problems as early as possible is essential and never-ending work in\ncontinuous delivery. If we find a problem in our exploratory testing, we must not only fix it, but then ask: How could\nwe have caught the problem with an automated acceptance test? When an acceptance test fails, we should ask: Could we\nhave written a unit test to catch this problem?"}),"\n",(0,i.jsx)(n.h3,{id:"work-in-small-batches",children:"Work in Small Batches"}),"\n",(0,i.jsx)(n.p,{children:"In traditional phased approaches to software development, handoffs from dev to test or test to IT operations consist of\nwhole releases: months worth of work by teams consisting of tens or hundreds of people."}),"\n",(0,i.jsx)(n.p,{children:"In continuous delivery, we take the opposite approach, and try and get every change in version control as far towards\nrelease as we can, getting comprehensive feedback as rapidly as possible."}),"\n",(0,i.jsx)(n.p,{children:"Working in small batches has many benefits. It reduces the time it takes to get feedback on our work, makes it easier to\ntriage and remediate problems, increases efficiency and motivation, and prevents us from succumbing to the sunk cost\nfallacy."}),"\n",(0,i.jsxs)(n.p,{children:["The reason we work in large batches is because of the large fixed cost of handing off changes. ",(0,i.jsx)(n.strong,{children:"A key goal of\ncontinuous delivery is to change the economics of the software delivery process to make it economically viable to work\nin small batches so we can obtain the many benefits of this approach"}),"."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsx)(n.p,{children:"A key goal of continuous delivery is to change the economics of the software delivery process to make it economically\nviable to work in small batches so we can obtain the many benefits of this approach"})}),"\n",(0,i.jsx)(n.h3,{id:"relentlessly-pursue-continuous-improvement",children:"Relentlessly Pursue Continuous Improvement"}),"\n",(0,i.jsxs)(n.p,{children:["Continuous improvement, or ",(0,i.jsx)(n.em,{children:"kaizen"})," in Japanese, is another key idea from the Lean movement.\n",(0,i.jsx)(n.a,{href:"http://www.amazon.com/dp/0071808019?tag=contindelive-20",children:"Taiichi Ohno"}),", a key figure in the history of the Toyota\ncompany, once said,"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:'"Kaizen opportunitites are infinite. Don\'t think you have made things better than before and be at ease\u2026 This would be\nlike the student who becomes proud because they bested their master two times out of three in fencing. Once you pick\nup the sprouts of kaizen ideas, it is important to have the attitude in our daily work that just underneath one kaizen\nidea is yet another one".'}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Don't treat transformation as a project to be embarked on and then completed so we can return to business as usual. The\nbest organizations are those where everybody treats improvement work as an essential part of their daily work, and where\nnobody is satisfied with the status quo."}),"\n",(0,i.jsx)(n.h3,{id:"everyone-is-responsible",children:"Everyone is Responsible"}),"\n",(0,i.jsx)(n.p,{children:'In high performing organizations, nothing is "somebody else\'s problem." Developers are responsible for the quality and\nstability of the software they build. Operations teams are responsible for helping developers build quality in. Everyone\nworks together to achieve the organizational level goals, rather than optimizing for what\u2019s best for their team or\ndepartment.'}),"\n",(0,i.jsx)(n.p,{children:"When people make local optimizations that reduce the overall performance of the organization, it's often due to systemic\nproblems such as poor management systems such as annual budgeting cycles, or incentives that reward the wrong behaviors.\nA classic example is rewarding developers for increasing their velocity or writing more code, and rewarding testers\nbased on the number of bugs they find."}),"\n",(0,i.jsx)(n.p,{children:"Most people want to do the right thing, but they will adapt their behaviour based on how they are rewarded. Therefore,\nit is very important to create fast feedback loops from the things that really matter: how customers react to what we\nbuild for them, and the impact on our organization."}),"\n",(0,i.jsx)(n.h2,{id:"foundations---prerequisites-for-continuous-delivery",children:"Foundations - Prerequisites for Continuous Delivery"}),"\n",(0,i.jsx)(n.h3,{id:"configuration-management",children:"Configuration Management"}),"\n",(0,i.jsx)(n.p,{children:"Automation plays a vital role in ensuring we can release software repeatably and reliably. One key goal is to take\nrepetitive manual processes like build, deployment, regression testing and infrastructure provisioning, and automate\nthem. In order to achieve this, we need to version control everything required to perform these processes, including\nsource code, test and deployment scripts, infrastructure and application configuration information, and the many\nlibraries and packages we depend upon. We also want to make it straightforward to query the current -and historical -\nstate of our environments."}),"\n",(0,i.jsx)(n.p,{children:"We have two overriding goals:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reproducibility"}),": We should be able to provision any environment in a fully automated fashion, and know that any\nnew environment reproduced from the same configuration is identical."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Traceability"}),": We should be able to pick any environment and be able to determine quickly and precisely the\nversions of every dependency used to create that environment. We also want to be able to compare previous versions of\nan environment and see what has changed between them."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"These capabilities give us several very important benefits:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Disaster recovery"}),": When something goes wrong with one of our environments, for example a hardware failure or a\nsecurity breach, we need to be able to reproduce that environment in a deterministic amount of time in order to be\nable to restore service."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Auditability"}),": In order to demonstrate the integrity of the delivery process, we need to be able to show the path\nbackwards from every deployment to the elements it came from, including their version. Comprehensive configuration\nmanagement, combined with deployment pipelines, enable this."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Higher quality"}),": The software delivery process is often subject to long delays waiting for development, testing\nand production environments to be prepared. When this can be done automatically from version control, we can get\nfeedback on the impact of our changes much more rapidly, enabling us to build quality in to our software."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Capacity management"}),": When we want to add more capacity to our environments, the ability to create new\nreproductions of existing servers is essential. This capability, using ",(0,i.jsx)(n.a,{href:"https://www.openstack.org/",children:"OpenStack"})," for\nexample, enables the horizontal scaling of modern cloud-based distributed systems."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Response to defects"}),": When we discover a critical defect, or a vulnerability in some component of our system, we\nwant to get a new version of our software released as quickly as possible. Many organizations have an emergency\nprocess for this type of change which goes faster by bypassing some of the testing and auditing. This presents an\nespecially serious dilemma in safety-critical systems. Our goal should be to be able to use our normal release\nprocess for emergency fixes - which is precisely what continuous delivery enables, on the basis of comprehensive\nconfiguration management."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["As environments become more complex and heterogeneous, it becomes progressively harder to achieve these goals. Achieving\nperfect reproducibility and traceability to the last byte for a complex enterprise system is impossible (apart from\nanything else, every real system has state). Thus a key part of configuration management is working to ",(0,i.jsx)(n.strong,{children:"simplify our\narchitecture, environments and processes"})," to reduce the investment required to achieve the desired benefits."]}),"\n",(0,i.jsx)(n.h4,{id:"configuration-management-learning-resources",children:"Configuration Management Learning Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.oreilly.com/library/view/infrastructure-as-code/9781491924334/",children:"Infrastructure as Code"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"http://www.infoq.com/presentations/scaling-operations-facebook",children:"Pedro Canahuati on scaling operations at Facebook"})}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"continuous-integration",children:"Continuous Integration"}),"\n",(0,i.jsx)(n.p,{children:"Combining the work of multiple developers is hard. Software systems are complex, and an apparently simple,\nself-contained change to a single file can easily have unintended consequences which compromise the correctness of the\nsystem. As a result, some teams have developers work isolated from each other on their own branches, both to keep\ntrunk/master stable, and to prevent them treading on each other\u2019s toes."}),"\n",(0,i.jsx)(n.p,{children:"However, over time these branches diverge from each other. While merging a single one of these branches into mainline is\nnot usually troublesome, the work required to integrate multiple long-lived branches into mainline is usually painful,\nrequiring significant amounts of re-work as conflicting assumptions of developers are revealed and must be resolved."}),"\n",(0,i.jsx)(n.p,{children:"Teams using long-lived branches often require code freezes, or even integration and stabilization phases, as they work\nto integrate these branches prior to a release. Despite modern tooling, this process is still expensive and\nunpredictable. On teams larger than a few developers, the integration of multiple branches requires multiple rounds of\nregression testing and bug fixing to validate that the system will work as expected following these merges. This problem\nbecomes exponentially more severe as team sizes grow, and as branches become more long-lived."}),"\n",(0,i.jsxs)(n.p,{children:["The practice of continuous integration was invented to address these problems. CI (continuous integration) follows the\nXP (extreme programming) principle that if something is painful, we should do it more often, and bring the pain forward.\nThus in CI developers integrate all their work into trunk (also known as mainline or master) on a regular basis (at\nleast daily). A set of automated tests is run both ",(0,i.jsx)(n.strong,{children:"before and after"})," the merge to validate that no regressions are\nintroduced. If these automated tests fail, the team stops what they are doing and someone fixes the problem immediately."]}),"\n",(0,i.jsx)(n.p,{children:"Thus we ensure that the software is always in a working state, and that developer branches do not diverge significantly\nfrom trunk. The benefits of continuous integration are very significant - higher levels of throughput, more stable\nsystems, and higher quality software. However the practice is still controversial, for two main reasons."}),"\n",(0,i.jsx)(n.p,{children:'First, it requires developers to break up large features and other changes into smaller, more incremental steps that can\nbe integrated into trunk/master. This is a paradigm shift for developers who are not used to working in this way. It also\ntakes longer to get large features completed. However in general we don\'t want to optimize for the speed at which\ndevelopers can declare their work "dev complete" on a branch. Rather, we want to be able to get changes reviewed,\nintegrated, tested and deployed as fast as possible - and this process is an order of magnitude faster and cheaper when\nthe changes are small and self-contained, and the branches they live on are short-lived. Working in small batches also\nensures developers get regular feedback on the impact of their work on the system as a whole - from other developers,\ntesters, customers, and automated performance and security tests\u2014which in turn makes any problems easier to detect,\ntriage, and fix.'}),"\n",(0,i.jsx)(n.p,{children:"Second, continuous integration requires a fast-running set of comprehensive automated unit tests. These tests should be\ncomprehensive enough to give a good level of confidence that the software will work as expected, while also running in a\nfew minutes or less. If the automated unit tests take longer to run, developers will not want to run them frequently,\nand they will become harder to maintain. Creating maintainable suites of automated unit tests is complex and is best done\nthrough test-driven development (TDD), in which developers write failing automated tests before they implement the code\nthat makes the tests pass. TDD has several benefits, the most important of which is that it ensures developers write code\nthat is modular and easy to test, reducing the maintenance cost of the resulting automated test suites. But TDD is still\nnot sufficiently widely practiced."}),"\n",(0,i.jsxs)(n.p,{children:["Despite these barriers, ",(0,i.jsx)(n.strong,{children:"helping software development teams implement continuous integration should be the number one\npriority for any organization"})," wanting to start the journey to continuous delivery. By creating rapid feedback loops\nand ensuring developers work in small batches, CI enables teams to build quality into their software, thus reducing the\ncost of ongoing software development, and increasing both the productivity of teams and the quality of the work they\nproduce."]}),"\n",(0,i.jsx)(n.h4,{id:"continuous-integration-learning-resources",children:"Continuous Integration Learning Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"http://www.amazon.com/dp/0321336380?tag=contindelive-20",children:"Paul Duvall's book on Continuous Integration"})}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"continuous-testing",children:"Continuous Testing"}),"\n",(0,i.jsx)(n.p,{children:"The key to building quality into our software is making sure we can get fast feedback on the impact of changes.\nTraditionally, extensive use was made of manual inspection of code changes and manual testing (testers following\ndocumentation describing the steps required to test the various functions of the system) in order to demonstrate the\ncorrectness of the system. This type of testing was normally done in a phase following \u201cdev complete\u201d. However this\nstrategy have several drawbacks:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Manual regression testing takes a long time and is relatively expensive to perform, creating a bottleneck that\nprevents us releasing software more frequently, and getting feedback to developers weeks (and sometimes months) after\nthey wrote the code being tested."}),"\n",(0,i.jsx)(n.li,{children:"Manual tests and inspections are not very reliable, since people are notoriously poor at performing repetitive tasks\nsuch as regression testing manually, and it is extremely hard to predict the impact of a set of changes on a complex\nsoftware system through inspection."}),"\n",(0,i.jsx)(n.li,{children:"When systems are evolving over time, as is the case in modern software products and services, we have to spend\nconsiderable effort updating test documentation to keep it up-to-date."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In order to build quality in to software, we need to adopt a\n",(0,i.jsx)(n.a,{href:"#different-types-of-software-testing",children:"different approach"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"The more features and improvements go into our code, the more we'll need to test to make sure that all our system works\nproperly. And then for each bug we fix, it would be wise to check that they don't get back in newer releases.\nAutomation is key to make this possible and writing tests sooner rather than later will become part of our development\nworkflow."}),"\n",(0,i.jsxs)(n.p,{children:["Once we have continuous integration and test automation in place, we create a\n",(0,i.jsx)(n.a,{href:"#the-deployment-pipeline",children:"deployment pipeline"}),". In the deployment pipeline pattern, every change runs a build that"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"creates packages that can be deployed to any environment and"}),"\n",(0,i.jsx)(n.li,{children:"runs unit tests (and possibly other tasks such as static analysis), giving feedback to developers in the space of a\nfew minutes."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Packages that pass this set of tests have more comprehensive automated acceptance tests run against them. Once we have\npackages that pass all the automated tests, they are available for deplyment to other environments."}),"\n",(0,i.jsx)(n.p,{children:"In the deployment pipeline, every change is effectively a release candidate. The job of the deployment pipeline is to\ncatch known issues. If we can't detect any known problems, we should feel totally comfortable releasing any packages\nthat have gone through it. If we aren't, or if we discover defects later, it means we need to improve our pipeline,\nperhaps adding or updating some tests."}),"\n",(0,i.jsx)(n.p,{children:"Our goal should be to find problems as soon as possible, and make the lead time from check-in to release as short as\npossible. Thus we want to parallelize the activities in the deployment pipeline, not have many stages executing in\nseries. If we discover a defect in the acceptance tests, we should be looking to improve our unit tests (most of our\ndefects should be discovered through unit testing)."}),"\n",(0,i.jsx)(n.h4,{id:"different-types-of-software-testing",children:"Different Types of Software Testing"}),"\n",(0,i.jsx)(n.h5,{id:"unit-tests",children:"Unit Tests"}),"\n",(0,i.jsx)(n.p,{children:"Unit tests are very low level and close to the source of an application. They consist in testing individual methods and\nfunctions of the classes, components, or modules used by our software. Unit tests are generally quite cheap to automate\nand can run very quickly by a continuous integration server."}),"\n",(0,i.jsx)(n.h5,{id:"integration-tests",children:"Integration Tests"}),"\n",(0,i.jsx)(n.p,{children:"Integration tests verify that different modules or services used by our application work well together. For example, it\ncan be testing the interaction with the database or making sure that microservices work together as expected. These\ntypes of tests are more expensive to run as they require multiple parts of the application to be up and running."}),"\n",(0,i.jsx)(n.h5,{id:"functional-tests",children:"Functional Tests"}),"\n",(0,i.jsx)(n.p,{children:"Functional tests focus on the business requirements of an application. They only verify the output of an action and do\nnot check the intermediate states of the system when performing that action."}),"\n",(0,i.jsx)(n.p,{children:"There is sometimes a confusion between integration tests and functional tests as they both require multiple components\nto interact with each other. The difference is that an integration test may simply verify that we can query the\ndatabase while a functional test would expect to get a specific value from the database as defined by the product\nrequirements."}),"\n",(0,i.jsx)(n.h5,{id:"end-to-end-tests",children:"End-to-End Tests"}),"\n",(0,i.jsx)(n.p,{children:"End-to-end testing replicates a user behavior with the software in a complete application environment. It verifies that\nvarious user flows work as expected and can be as simple as loading a web page or logging in or much more complex\nscenarios verifying email notifications, online payments, etc..."}),"\n",(0,i.jsx)(n.p,{children:"End-to-end tests are very useful, but they're expensive to perform and can be hard to maintain when they're automated.\nIt is recommended to have a few key end-to-end tests and rely more on lower level types of testing (unit and\nintegration tests) to be able to quickly identify breaking changes."}),"\n",(0,i.jsx)(n.h5,{id:"acceptance-tests",children:"Acceptance Tests"}),"\n",(0,i.jsx)(n.p,{children:"Acceptance tests are formal tests that verify if a system satisfies business requirements. They require the entire\napplication to be running while testing and focus on replicating user behaviors. But they can also go further and\nmeasure the performance of the system and reject changes if certain goals are not met."}),"\n",(0,i.jsx)(n.h5,{id:"performance-tests",children:"Performance Tests"}),"\n",(0,i.jsx)(n.p,{children:"Performance tests evaluate how a system performs under a particular workload. These tests help to measure the\nreliability, speed, scalability, and responsiveness of an application. For instance, a performance test can observe\nresponse times when executing a high number of requests, or determine how a system behaves with a significant amount of\ndata. It can determine if an application meets performance requirements, locate bottlenecks, measure stability during\npeak traffic, and more."}),"\n",(0,i.jsx)(n.h5,{id:"smoke-tests",children:"Smoke Tests"}),"\n",(0,i.jsx)(n.p,{children:"Smoke tests are basic tests that check the basic functionality of an application. They are meant to be quick to\nexecute, and their goal is to give us the assurance that the major features of our system are working as expected."}),"\n",(0,i.jsx)(n.p,{children:"Smoke tests can be useful right after a new build is made to decide whether or not we can run more expensive tests, or\nright after a deployment to make sure that they application is running properly in the newly deployed environment."}),"\n",(0,i.jsx)(n.h2,{id:"implementing-continuous-delivery",children:"Implementing Continuous Delivery"}),"\n",(0,i.jsx)(n.p,{children:"Organizations attempting to deploy continuous delivery tend to make two common mistakes. The first is to treat\ncontinuous delivery as an end-state, a goal in itself. The second is to spend a lot of time and energy worrying about\nwhat products to use."}),"\n",(0,i.jsx)(n.h3,{id:"evolutionary-architecture",children:"Evolutionary Architecture"}),"\n",(0,i.jsx)(n.p,{children:"In the context of enterprise architecture there are typically multiple attributes we are concerned about, for example\navailability, security, performance, usability and so forth. In continuous delivery, we introduce two new architectural\nattributes:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"testability"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"deployability"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In a ",(0,i.jsx)(n.em,{children:"testable"})," architecture, we design our software such that most defects can (in principle, at least) be discovered\nby developers by running automated tests on their workstations. We shouldn\u2019t need to depend on complex, integrated\nenvironments in order to do the majority of our acceptance and regression testing."]}),"\n",(0,i.jsxs)(n.p,{children:["In a ",(0,i.jsx)(n.em,{children:"deployable"})," architecture, deployments of a particular product or service can be performed independently and in a\nfully automated fashion, without the need for significant levels of orchestration. Deployable systems can typically be\nupgraded or reconfigured with zero or minimal downtime."]}),"\n",(0,i.jsx)(n.p,{children:'Where testability and deployability are not prioritized, we find that much testing requires the use of complex,\nintegrated environments, and deployments are "big bang" events that require that many services are released at the same\ntime due to complex interdependencies. These "big bang" deployments require many teams to work together in a carefully\norchestrated fashion with many hand-offs, and dependencies between hundreds or thousands of tasks. Such deployments\ntypically take many hours or even days, and require scheduling significant downtime.'}),"\n",(0,i.jsx)(n.p,{children:"Designing for testability and deployability starts with ensuring our products and services are composed of\nloosely-coupled, well-encapsulated components or modules"}),"\n",(0,i.jsx)(n.p,{children:"We can define a well-designed modular architecture as one in which it is possible to test or deploy a single component\nor service on its own, with any dependencies replaced by a suitable test double, which could be in the form of a virtual\nmachine, a stub, or a mock. Each component or service should be deployable in a fully automated fashion on developer\nworkstations, test environments, or in production. In a well-designed architecture, it is possible to get a high level of\nconfidence the component is operating properly when deployed in this fashion."}),"\n",(0,i.jsxs)(n.admonition,{title:"Test Double",type:"info",children:[(0,i.jsx)(n.p,{children:"Test Double is a generic term for any case where you replace a production object for testing purposes. There are various\nkinds of double:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dummy"})," objects are passed around but never actually used. Usually they are just used to fill parameter lists."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fake"})," objects actually have working implementations, but usually take some shortcut which makes them not suitable\nfor production (an InMemoryTestDatabase is a good example)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stubs"})," provide canned answers to calls made during the test, usually not responding at all to anything outside\nwhat's programmed in for the test."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Spies"})," are stubs that also record some information based on how they were called. One form of this might be an email\nservice that records how many messages it was sent."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mocks"})," are pre-programmed with expectations which form a specification of the calls they are expected to receive.\nThey can throw an exception if they receive a call they don't expect and are checked during verification to ensure\nthey got all the calls they were expecting."]}),"\n"]})]}),"\n",(0,i.jsx)(n.p,{children:"Any true service-oriented architecture should have these properties\u2014but unfortunately many do not. However, the\nmicroservices movement has explicitly prioritized these architectural properties."}),"\n",(0,i.jsx)(n.p,{children:"Of course, many organizations are living in a world where services are distinctly hard to test and deploy. Rather than\nre-architecting everything, we recommend an iterative approach to improving the design of enterprise system, sometimes\nknown as evolutionary architecture. In the evolutionary architecture paradigm, we accept that successful products and\nservices will require re-architecting during their lifecycle due to the changing requirements placed on them."}),"\n",(0,i.jsx)(n.p,{children:'One pattern that is particularly valuable in this context is the strangler application. In this pattern, we iteratively\nreplace a monolithic architecture with a more componentized one by ensuring that new work is done following the\nprinciples of a service-oriented architecture, while accepting that the new architecture may well delegate to the system\nit is replacing. Over time, more and more functionality will be performed in the new architecture, and the old system\nbeing replaced is "strangled".'}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(4225).A+"",width:"1458",height:"748"})}),"\n",(0,i.jsx)(n.h3,{id:"patterns",children:"Patterns"}),"\n",(0,i.jsx)(n.h4,{id:"the-deployment-pipeline",children:"The Deployment Pipeline"}),"\n",(0,i.jsxs)(n.p,{children:["The key pattern introduced in continuous delivery is the ",(0,i.jsx)(n.strong,{children:"deployment pipeline"}),". Our goal was to make deployment to any\nenvironment a fully automated, scripted process that could be performed on demand in minutes. We wanted to be able to\nconfigure testing and production environments purely from configuration files stored in version control. The apparatus\nwe used to perform these tasks became known as ",(0,i.jsx)(n.em,{children:"deployment pipelines"})]}),"\n",(0,i.jsx)(n.p,{children:"In the deployment pipeline pattern, every change in version control triggers a process (usually in a CI server) which\ncreates deployable packages and runs automated unit tests and other validations such as static code analysis. This first\nstep is optimized so that it takes only a few minutes to run. If this initial commit stage fails, the problem must be\nfixed immediately; nobody should check in more work on a broken commit stage. Every passing commit stage triggers the\nnext step in the pipeline, which might consist of a more comprehensive set of automated tests. Versions of the software\nthat pass all the automated tests can then be deployed to production."}),"\n",(0,i.jsxs)(n.p,{children:["Deployment pipelines tie together ",(0,i.jsx)(n.a,{href:"#configuration-management",children:"configuration management"}),",\n",(0,i.jsx)(n.a,{href:"#continuous-integration",children:"continuous integration"})," and ",(0,i.jsx)(n.a,{href:"#continuous-testing",children:"test"})," and deployment automation in a\nholistic, powerful way that works to improve software quality, increase stability, and reduce the time and cost required\nto make incremental changes to software, whatever domain we're operating in. When building a deployment pipeline, the\nfollowing practices become valuable:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Only build packages once"}),". We want to be sure the thing we're deploying is the same thing we've tested throughout\nthe deployment pipeline, so if a deployment fails we can eliminate the packages as the source of the failure."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deploy the same way to every environment, including development"}),". This way, we test the deployment process many,\nmany times before it gets to production, and again, we can eliminate it as the source of any problems."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Smoke test your deployments"}),". Have a script that validates all your application's dependencies are available, at\nthe location you have configured your application. Make sure your application is running and available as part of the\ndeployment process."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Keep your environments similar"}),". Although they may differ in hardware configuration, they should have the same\nversion of the operating system and middleware packages, and they should be configured in the same way. This has\nbecome much easier to achieve with modern virtualization and container technology."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"With the advent of infrastructure as code, it has became possible to use deployment pipelines to create a fully\nautomated process for taking all kinds of changes\u2014including database and infrastructure changes"}),"\n",(0,i.jsx)(n.h3,{id:"patterns-for-low-risk-releases",children:"Patterns for Low-Risk Releases"}),"\n",(0,i.jsxs)(n.p,{children:["In the context of web-based systems there are a number of patterns that can be applied to further reduce the risk of\ndeployments. Michael Nygard also describes a number of important software design patterns which are instrumental in\ncreating resilient large-scale systems in his book\n",(0,i.jsx)(n.a,{href:"http://www.amazon.com/dp/0978739213?tag=contindelive-20",children:"Release It!"})]}),"\n",(0,i.jsx)(n.p,{children:"The 3 key principles that enable low-risk releases are"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Optimize for Resilience"}),". Once we accept that failures are inevitable, we should start to move away from the idea\nof investing all our effort in preventing problems, and think instead about how to restore service as rapidly as\npossible when something goes wrong. Furthermore, when an accident occurs, we should treat it as a learning\nopportunity. Resilience isn't just a feature of our systems, it's a characteristic of a team's culture. High\nperformance organizations are constantly working to improve the resilience of their systems by trying to break them\nand implementing the lessons learned in the course of doing so."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Low-risk Releases are Incremental"}),". Our goal is to architect our systems such that we can release individual\nchanges (including database changes) independently, rather than having to orchestrate big-bang releases due to tight\ncoupling between multiple different systems."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Focus on Reducing Batch Size"}),". Counterintuitively, deploying to production more frequently actually reduces the\nrisk of release when done properly, simply because the amount of change in each deployment is smaller. When each\ndeployment consists of tens of lines of code or a few configuration settings, it becomes much easier to perform root\ncause analysis and restore service in the case of an incident. Furthermore, because we practice the deployment\nprocess so frequently, we\u2019re forced to simplify and automate it which further reduces risk."]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},9908:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/blue-green-deployments-5a0c344650154229cb4af876bd9f7f4a.png"},4225:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/strangler-a317ed534afb581ac45d77ac9a89616a.png"},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>r});var i=t(6540);const s={},o=i.createContext(s);function a(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);